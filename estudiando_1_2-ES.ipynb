{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cfc033",
   "metadata": {},
   "source": [
    "# APLICACI√ìN WEB DE TRANSCRIPCI√ìN DE VOZ A TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ea619",
   "metadata": {},
   "source": [
    "![Logo de Python](./text2speech.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4df2c",
   "metadata": {},
   "source": [
    "# Caracter√≠sticas Arquitect√≥nicas Principales:\n",
    "### 1. Soporte Dual de Modelos:\n",
    "- Primario: Pipeline de Hugging Face Transformers\n",
    "- Alternativo: Biblioteca Whisper de OpenAI\n",
    "- Cambio autom√°tico si falla el m√©todo primario\n",
    "\n",
    "### 2. M√©todos Duales de Entrada:\n",
    "- Grabaci√≥n con Micr√≥fono: Captura de audio en tiempo real\n",
    "- Subida de ficheros: Archivos de audio pregrabados\n",
    "- Sistema de prioridad: Las subidas anulan las grabaciones\n",
    "\n",
    "### 3. Gesti√≥n de Archivos:\n",
    "- Creaci√≥n autom√°tica del directorio para guardar las grabaciones\n",
    "- Crea ficheros √∫nicos basados en marcas de tiempo\n",
    "- Estandarizaci√≥n de audio (mono, 16kHz)\n",
    "- Visualizaci√≥n clara de las rutas de los ficheros\n",
    "\n",
    "### 4. Manejo de Errores:\n",
    "- Informa al fallar la carga del modelo\n",
    "- Validaci√≥n de entrada\n",
    "- Resoluci√≥n de conflictos de puertos\n",
    "- Mensajes de error amigables para el usuario\n",
    "\n",
    "### 5. Experiencia de Usuario:\n",
    "- Dise√±o limpio de dos columnas\n",
    "- Separaci√≥n clara entrada/salida\n",
    "- Capacidad de compartir p√∫blicamente (Gradio UI)\n",
    "\n",
    "### 6. Desarrollo\n",
    "- C√≥digo ipynb (Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ff25e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# APLICACI√ìN WEB DE TRANSCRIPCI√ìN DE VOZ A TEXTO\n",
    "#==============================================================\n",
    "# Tecnolog√≠as:\n",
    "# - Gradio: interfaz web\n",
    "# - Whisper: reconocimiento autom√°tico del habla (ASR)\n",
    "# - PyTorch: detecci√≥n de GPU\n",
    "# - FFmpeg: normalizaci√≥n y guardado de audio\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Grabar audio desde micr√≥fono\n",
    "# - Subir archivos de audio\n",
    "# - Transcribir voz a texto\n",
    "# - Guardar autom√°ticamente el audio procesado\n",
    "# - Interfaz centrada con columnas fijas y mismo tama√±o\n",
    "# =============================================================\n",
    "\n",
    "# =================================\n",
    "# 1. IMPORTACI√ìN DE LIBRER√çAS\n",
    "# =================================\n",
    "\n",
    "import gradio as gr               # Gradio permite crear interfaces web interactivas de forma sencilla\n",
    "from transformers import pipeline # pipeline simplifica el uso de modelos preentrenados de Hugging Face\n",
    "import torch                      # Torch se usa aqu√≠ para comprobar si hay GPU disponible (CUDA)\n",
    "import os                         # os permite interactuar con el sistema operativo (rutas, carpetas)\n",
    "import ffmpeg                     # ffmpeg se usa para convertir y normalizar audio\n",
    "import datetime                   # datetime se usa para generar timestamps √∫nicos\n",
    "import base64                     # para crear el logo en memoria\n",
    "import socket                     # para verificar si hay un puerto URL libre\n",
    "import json                       # para la cache a usar en los fichero que se cargan\n",
    "import time                       # usar la hora del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "29685e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üé§ INICIALIZANDO TRANSCRIPTOR DE VOZ\n",
      "============================================================\n",
      "Dispositivo seleccionado: cuda\n",
      "üì• Cargando modelo Whisper (openai/whisper-small)\n",
      "‚úÖ Idiomas soportados: ingl√©s, espa√±ol, portugu√©s, chino, italiano + 94 m√°s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Whisper cargado mediante Transformers ¬°EXITOSAMENTE!\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 2. INICIALIZACION DEL MODELO\n",
    "# =================================\n",
    "\n",
    "print(\"=\" * 60)                                # Imprime una l√≠nea decorativa en consola\n",
    "print(\"üé§ INICIALIZANDO TRANSCRIPTOR DE VOZ\") # Mensaje informativo\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -----------------------------\n",
    "# SELECCI√ìN DEL DISPOSITIVO\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # torch.cuda.is_available() devuelve True si hay GPU compatible\n",
    "print(f\"Dispositivo seleccionado: {device}\")            # Se informa al usuario qu√© dispositivo se est√° usando\n",
    "\n",
    "# -----------------------------\n",
    "# CARGA DEL MODELO WHISPER\n",
    "# -----------------------------\n",
    "# Modelo PRINCIPAL para 99 idiomas\n",
    "print(\"üì• Cargando modelo Whisper (openai/whisper-small)\")\n",
    "print(\"‚úÖ Idiomas soportados: ingl√©s, espa√±ol, portugu√©s, chino, italiano + 94 m√°s\")\n",
    "\n",
    "try:\n",
    "    # Intentar cargar el modelo Whisper usando el pipeline de Hugging Face (hf) transformers\n",
    "    # \"automatic-speech-recognition\" es el tipo de tarea para conversi√≥n de voz a texto\n",
    "    # \"openai/whisper-small\" es una variante espec√≠fica del modelo Whisper PRE-ENTRENADO\n",
    "    # El par√°metro device asegura que el modelo se cargue en GPU si est√° disponible\n",
    "    \n",
    "    # Carga el modelo preentrenado usando HF\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=\"openai/whisper-small\",\n",
    "        device=device)\n",
    "\n",
    "    # Flag para rastrear qu√© implementaci√≥n del modelo se est√° usando\n",
    "    USE_WHISPER = False # Usando el pipeline de transformers, no la biblioteca OpenAI Whisper\n",
    "    \n",
    "    print(\"‚úî Whisper cargado mediante Transformers ¬°EXITOSAMENTE!\") # Mensaje de √©xito para la pipeline de transformers\n",
    "\n",
    "except Exception:\n",
    "    # Plan B: Si falla el pipeline de transformers (dependencias, versiones, etc.), usar la biblioteca OpenAI Whisper directamente\n",
    "    # se usa la librer√≠a oficial de OpenAI Whisper\n",
    "    import whisper\n",
    "\n",
    "    # Cargar el modelo Whisper \"base\" (variante m√°s peque√±a que equilibra velocidad/precisi√≥n)\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "    USE_WHISPER = True # Flag que indica que estamos usando la biblioteca OpenAI Whisper\n",
    "\n",
    "    print(\"‚úî Whisper cargado mediante OpenAI (fallback)\") # Informar al usuario sobre el m√©todo alternativo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "85f4470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta de grabaciones: c:\\Users\\castr\\Desktop\\syncSchool\\OBS\\10_Speech-Next_Analytics\\_recordings\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 3. DIRECTORIO DE GRABACIONES\n",
    "# =================================\n",
    "\n",
    "# Nombre de la carpeta donde se guardar√°n los audios\n",
    "RECORDINGS_DIR = \"_recordings\"\n",
    "\n",
    "# os.makedirs crea la carpeta si no existe\n",
    "# exist_ok=True evita error si el directorio ya existe\n",
    "os.makedirs(RECORDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Mostrar ruta absoluta para referencia del usuario (ruta completa desde la ra√≠z)\n",
    "print(f\"Carpeta de grabaciones: {os.path.abspath(RECORDINGS_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "123ccb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# 4. FUNCI√ìN DE TRANSCRIPCI√ìN\n",
    "# =================================\n",
    "\n",
    "def transcribe_audio_ori(audio_path, uploaded_file=None):\n",
    "    \"\"\"\n",
    "    Transcribe audio desde grabaci√≥n de micr√≥fono (graba la voz en un fichero antes de trancribir) o archivo cargado a memoria.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    audio_path : str\n",
    "        Ruta del archivo de audio desde la grabaci√≥n usando el micr√≥fono\n",
    "        \n",
    "    uploaded_file : str, opcional\n",
    "        Ruta del archivo de audio subido (tiene prioridad sobre audio_path)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple : (texto_transcrito, informaci√≥n_del_archivo)\n",
    "        Transcripci√≥n de texto y detalles sobre el archivo guardado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sistema de prioridad: archivo subido anula la grabaci√≥n del micr√≥fono\n",
    "    # Si el usuario sube un archivo, se usa en lugar de la grabaci√≥n\n",
    "    if uploaded_file is not None:\n",
    "        audio_path = uploaded_file\n",
    "\n",
    "    # Validaci√≥n b√°sica: si no hay audio, se devuelve mensaje\n",
    "    if not audio_path:\n",
    "        return \"No hay audio para transcribir\", \"No hay archivo\" # Mensaje de error si no hay fichero de audio\n",
    "\n",
    "    try:\n",
    "        # Se genera un timestamp para evitar sobrescribir archivos\n",
    "        # Genera nombre de fichero √∫nico mediante fecha_hora\n",
    "        # Formato: A√±oMesD√≠a_HoraMinutoSegundo (ej: 20240115_143025)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Nombre del fichero\n",
    "        if uploaded_file:\n",
    "            # Para ficheros subidos: preservar nombre original con marca de tiempo\n",
    "            original_name = os.path.basename(uploaded_file)        # Obtener solo el nombre del fichero sin ruta\n",
    "            name_without_ext = os.path.splitext(original_name)[0]  # Remover extensi√≥n del fichero\n",
    "            filename = f\"{name_without_ext}_{timestamp}.wav\"       # Agregar marca de tiempo y extensi√≥n .wav\n",
    "        else:\n",
    "            # Para grabaciones de micr√≥fono: nombre gen√©rico con marca de tiempo\n",
    "            filename = f\"recording_{timestamp}.wav\"\n",
    "\n",
    "        # Ruta completa donde se guarda el audio\n",
    "        save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "\n",
    "        # -------------------------\n",
    "        # L√ìGICA DE TRANSCRIPCI√ìN\n",
    "        # -------------------------\n",
    "        # Elegir m√©todo de transcripci√≥n basado en qu√© modelo se carg√≥ exitosamente\n",
    "        if USE_WHISPER:\n",
    "            # Usar biblioteca OpenAI Whisper\n",
    "            result = whisper_model.transcribe(audio_path) # Devuelve un diccionario con clave \"text\"\n",
    "            text = result.get(\"text\", \"\")                 # Extrae el texto de transcripci√≥n\n",
    "        else:\n",
    "            # El pipeline Transformers de HF devuelve un diccionario\n",
    "            result = pipe(audio_path)     # Devuelve diccionario con clave \"text\"\n",
    "            text = result.get(\"text\", \"\") # Extrae el texto de transcripci√≥n\n",
    "\n",
    "        # ====================================================================\n",
    "        # PROCESAMIENTO Y GUARDADO DE AUDIO\n",
    "        # ====================================================================\n",
    "        \n",
    "        # Convertir y guardar audio a formato estandarizado usando ffmpeg\n",
    "        # ffmpeg.input() - Especifica fichero de audio de entrada\n",
    "        # .output() - Define par√°metros de salida:\n",
    "        #   save_path - Ruta del fichero de destino\n",
    "        #   ac=1 - Convertir a mono (1 canal de audio)\n",
    "        #   ar=16000 - Remuestrear a 16kHz (√≥ptimo para reconocimiento de voz)\n",
    "        # .run(quiet=True) - Ejecutar conversi√≥n silenciosamente (sin salida en consola)\n",
    "        \n",
    "        # -------------------------\n",
    "        # NORMALIZACI√ìN DEL AUDIO\n",
    "        # -------------------------\n",
    "\n",
    "        # ffmpeg.input carga el audio original\n",
    "        # output:\n",
    "        # - ac=1 ‚Üí mono\n",
    "        # - ar=16000 ‚Üí 16 kHz\n",
    "        ffmpeg.input(audio_path).output(save_path,\n",
    "                                        ac=1,\n",
    "                                        ar=16000).run(quiet=True)\n",
    "\n",
    "        # Ruta absoluta (ruta completa desde la ra√≠z)\n",
    "        full_path = os.path.abspath(save_path)\n",
    "        \n",
    "        # Crear mensaje de informaci√≥n del fichero amigable para el usuario\n",
    "        file_info = f\"Guardado en: {full_path}\"\n",
    "        \n",
    "        # Retornar resultados: texto de transcripci√≥n (sin espacios en blanco) e informaci√≥n del fichero\n",
    "        return text.strip(), file_info\n",
    "\n",
    "    except Exception as e:\n",
    "        # Captura cualquier error y lo devuelve a la UI\n",
    "        # Manejo de errores: retornar mensaje de error si algo falla\n",
    "        return f\"Error durante la transcripci√≥n: {str(e)}\", \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08282250",
   "metadata": {},
   "source": [
    "## CSS para:\n",
    "‚úÖ Efectos visuales (sombras, gradientes, transiciones)\n",
    "\n",
    "‚úÖ Responsive complejo (media queries)\n",
    "\n",
    "‚úÖ Control pixel-perfect\n",
    "\n",
    "‚úÖ Temas y estilos personalizados\n",
    "\n",
    "‚úÖ Animaciones y micro-interacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e6706cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 5. Definir par√°metros CSS\n",
    "# =====================================\n",
    "\n",
    "CSS = \"\"\"\n",
    "/* Variables globales */\n",
    ":root{--col-width:600px;\n",
    "      --gap:24px;\n",
    "      --radius:8px;\n",
    "      --shadow:0 6px 18px rgba(0,0,0,.08)}\n",
    "\n",
    "/* Centrado general */\n",
    ".gradio-root{display:flex;\n",
    "             justify-content:center}\n",
    "\n",
    "/* Contenedor com√∫n de filas */\n",
    ".center-wrapper{display:flex;\n",
    "                gap:var(--gap);\n",
    "                justify-content:center;\n",
    "                align-items:flex-start;\n",
    "                max-width:calc(var(--col-width)*2 + var(--gap));\n",
    "                width:100%;\n",
    "                margin:16px auto}\n",
    "\n",
    "/* Columnas est√°ndar */\n",
    ".equal-column{width:var(--col-width)!important;\n",
    "              background:#fff;\n",
    "              border-radius:var(--radius);\n",
    "              box-shadow:var(--shadow);\n",
    "              padding:12px}\n",
    "\n",
    "/* Columna que ocupa ambas */\n",
    ".span-two-columns{width:calc(var(--col-width)*2 + var(--gap))!important}\n",
    "\n",
    "/* Bot√≥n ancho completo */\n",
    "#transcribe-btn{width:100%!important}\n",
    "\n",
    "/* Responsive */\n",
    "@media (max-width:1240px){.center-wrapper{flex-direction:column},\n",
    "                          .equal-column,\n",
    "                          .span-two-columns{width:100%!important}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cbbe9",
   "metadata": {},
   "source": [
    "# Configurar columnas Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fa184f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el comportamiento de las columnas en Gradio\n",
    "LAYOUT = {\"col_l\": {\"scale\": 1, \"min_width\": 600},\n",
    "          \"col_r\": {\"scale\": 1, \"min_width\": 600}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ca0c3",
   "metadata": {},
   "source": [
    "# Cache to use the uploaded files once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c7d89d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCache:\n",
    "    \"\"\"Manage audio file cache\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir=RECORDINGS_DIR):\n",
    "        self.cache_dir = cache_dir\n",
    "        self.cache_file = os.path.join(cache_dir, \"cache_index.json\")\n",
    "        self.cache = self.load_cache()\n",
    "        \n",
    "    def load_cache(self):\n",
    "        \"\"\"Load cache index from file\"\"\"\n",
    "        if os.path.exists(self.cache_file):\n",
    "            with open(self.cache_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def save_cache(self):\n",
    "        \"\"\"Save cache index to file\"\"\"\n",
    "        with open(self.cache_file, 'w') as f:\n",
    "            json.dump(self.cache, f, indent=2)\n",
    "    \n",
    "    def get_cached_file(self, original_path):\n",
    "        \"\"\"Get cached processed file if exists\"\"\"\n",
    "        file_hash = self._get_file_signature(original_path)\n",
    "        \n",
    "        if file_hash in self.cache:\n",
    "            cached_path = self.cache[file_hash]['processed_path']\n",
    "            # Check if file still exists\n",
    "            if os.path.exists(cached_path):\n",
    "                return cached_path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def add_to_cache(self, original_path, processed_path):\n",
    "        \"\"\"Add file to cache\"\"\"\n",
    "        file_hash = self._get_file_signature(original_path)\n",
    "        self.cache[file_hash] = {\n",
    "            'original': original_path,\n",
    "            'processed_path': processed_path,\n",
    "            'timestamp': time.time(),\n",
    "            'size': os.path.getsize(processed_path)\n",
    "        }\n",
    "        self.save_cache()\n",
    "    \n",
    "    def _get_file_signature(self, file_path):\n",
    "        \"\"\"Create unique signature for file\"\"\"\n",
    "        stat = os.stat(file_path)\n",
    "        # Combine filename, size, and modification time\n",
    "        return f\"{os.path.basename(file_path)}_{stat.st_size}_{int(stat.st_mtime)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2f164fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs the cache\n",
    "audio_cache = AudioCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b3c2bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path, uploaded_file=None):\n",
    "    \"\"\"Smart file management: Don't create duplicates for uploaded files\"\"\"\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        audio_path = uploaded_file\n",
    "\n",
    "    if not audio_path:\n",
    "        return \"No hay audio para transcribir\", \"No hay archivo\"\n",
    "\n",
    "    try:\n",
    "        # ==========================================\n",
    "        # ALWAYS TRANSCRIBE FROM ORIGINAL FIRST\n",
    "        # ==========================================\n",
    "        print(f\"üìù Transcribiendo: {os.path.basename(audio_path)}\")\n",
    "        \n",
    "        if USE_WHISPER:\n",
    "            result = whisper_model.transcribe(audio_path)\n",
    "            text = result.get(\"text\", \"\")\n",
    "        else:\n",
    "            result = pipe(audio_path)\n",
    "            text = result.get(\"text\", \"\")\n",
    "        \n",
    "        # ==========================================\n",
    "        # SMART FILE PROCESSING\n",
    "        # ==========================================\n",
    "        if uploaded_file:\n",
    "            original_name = os.path.basename(audio_path)\n",
    "            name_without_ext = os.path.splitext(original_name)[0]\n",
    "            original_ext = os.path.splitext(original_name)[1].lower()\n",
    "            \n",
    "            # Determine if we already have this file processed\n",
    "            save_path = None\n",
    "            file_info = \"\"\n",
    "            \n",
    "            # Check recordings directory for matching files\n",
    "            for file in os.listdir(RECORDINGS_DIR):\n",
    "                file_lower = file.lower()\n",
    "                \n",
    "                # Case 1: Exact same filename already exists (rare but possible)\n",
    "                if file == original_name:\n",
    "                    save_path = os.path.join(RECORDINGS_DIR, file)\n",
    "                    file_info = f\"Archivo ya existe en grabaciones: {file}\"\n",
    "                    print(f\"‚úÖ Archivo ya existe: {file}\")\n",
    "                    break\n",
    "                \n",
    "                # Case 2: Processed WAV version exists (e.g., audio.mp3 -> audio.wav)\n",
    "                elif (file_lower.startswith(name_without_ext.lower()) and \n",
    "                      file_lower.endswith('.wav') and\n",
    "                      not file_lower.startswith('recording_')):\n",
    "                    save_path = os.path.join(RECORDINGS_DIR, file)\n",
    "                    file_info = f\"Usando versi√≥n procesada existente: {file}\"\n",
    "                    print(f\"‚úÖ Versi√≥n procesada existe: {file}\")\n",
    "                    break\n",
    "            \n",
    "            if not save_path:\n",
    "                # No existing file found, create processed version\n",
    "                if original_ext == '.wav':\n",
    "                    # If uploading a WAV file, check if it's already in the right format\n",
    "                    # before deciding to copy or process it\n",
    "                    try:\n",
    "                        import soundfile as sf\n",
    "                        info = sf.info(audio_path)\n",
    "                        \n",
    "                        # Check if it's already mono, 16kHz\n",
    "                        if info.channels == 1 and info.samplerate == 16000:\n",
    "                            # Already in correct format, just copy it\n",
    "                            filename = original_name\n",
    "                            save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "                            \n",
    "                            # Copy file instead of reprocessing\n",
    "                            import shutil\n",
    "                            shutil.copy2(audio_path, save_path)\n",
    "                            \n",
    "                            file_info = f\"Archivo WAV ya en formato correcto, copiado: {filename}\"\n",
    "                            print(f\"üìã WAV ya en formato correcto, copiado: {filename}\")\n",
    "                        else:\n",
    "                            # Needs processing\n",
    "                            filename = f\"{name_without_ext}.wav\"\n",
    "                            save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "                            \n",
    "                            ffmpeg.input(audio_path).output(save_path,\n",
    "                                                          ac=1,\n",
    "                                                          ar=16000).run(quiet=True)\n",
    "                            \n",
    "                            file_info = f\"WAV procesado a formato est√°ndar: {filename}\"\n",
    "                            print(f\"üîß WAV procesado a formato est√°ndar: {filename}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        # Fallback: just process it\n",
    "                        filename = f\"{name_without_ext}.wav\"\n",
    "                        save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "                        \n",
    "                        ffmpeg.input(audio_path).output(save_path,\n",
    "                                                      ac=1,\n",
    "                                                      ar=16000).run(quiet=True)\n",
    "                        \n",
    "                        file_info = f\"Procesado: {filename}\"\n",
    "                        print(f\"üíæ Procesado (fallback): {filename}\")\n",
    "                        \n",
    "                else:\n",
    "                    # For non-WAV files (mp3, m4a, etc.)\n",
    "                    filename = f\"{name_without_ext}.wav\"\n",
    "                    save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "                    \n",
    "                    ffmpeg.input(audio_path).output(save_path,\n",
    "                                                  ac=1,\n",
    "                                                  ar=16000).run(quiet=True)\n",
    "                    \n",
    "                    file_info = f\"Convertido a WAV: {filename}\"\n",
    "                    print(f\"üîÑ Convertido a WAV: {filename}\")\n",
    "                    \n",
    "        else:\n",
    "            # For recordings: Always create new file with timestamp\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"recording_{timestamp}.wav\"\n",
    "            save_path = os.path.join(RECORDINGS_DIR, filename)\n",
    "            \n",
    "            ffmpeg.input(audio_path).output(save_path,\n",
    "                                          ac=1,\n",
    "                                          ar=16000).run(quiet=True)\n",
    "            \n",
    "            file_info = f\"Grabaci√≥n nueva: {filename}\"\n",
    "            print(f\"üé§ Nueva grabaci√≥n: {filename}\")\n",
    "        \n",
    "        full_path = os.path.abspath(save_path)\n",
    "        file_info += f\"\\nüìÅ Ubicaci√≥n: {full_path}\"\n",
    "        \n",
    "        return text.strip(), file_info\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return f\"Error durante la transcripci√≥n: {str(e)}\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ebfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\castr\\AppData\\Local\\Temp\\ipykernel_21340\\694947360.py:5: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: css. Please pass these parameters to launch() instead.\n",
      "  demo = gr.Blocks(css=CSS)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6 CONFIGURACI√ìN DE LA INTERFAZ DE USUARIO GRADIO\n",
    "# ============================================================================\n",
    "# Crear interfaz de Bloques de Gradio (m√°s flexible que la Interface simple)\n",
    "demo = gr.Blocks(css=CSS)\n",
    "\n",
    "# Definir dise√±o y componentes de la UI\n",
    "with demo:\n",
    "\n",
    "    # ENCABEZADO\n",
    "    with gr.Row(elem_classes=\"center-wrapper\"):\n",
    "        with gr.Column(elem_classes=[\"equal-column\"]):\n",
    "            # permite descargar, ampliar y compartir la imagen\n",
    "            # gr.Image(value='./text2speech.jpg', interactive=False, type=\"filepath\")\n",
    "            \n",
    "            # solo para ficheros locales, no vale para internet\n",
    "            # gr.Markdown(\"\"\"\n",
    "            #     <div style=\"pointer-events: none; user-select: none; width:600px; margin:auto;\">\n",
    "            #         <img src=\"./text2speech.jpg\" style=\"width:100%; height:auto; user-drag:none; pointer-events:none;\">\n",
    "            #     </div>\n",
    "            #     \"\"\")\n",
    "\n",
    "            # Abrir el logo y codificarlo a base64\n",
    "            with open(\"./text2speech.jpg\", \"rb\") as f:\n",
    "                data = f.read()\n",
    "            logo_b64 = base64.b64encode(data).decode()\n",
    "\n",
    "            # Insertar logo en Markdown/HTML\n",
    "            gr.Markdown(f\"\"\"\n",
    "                        <div style=\"pointer-events: none; user-select: none; width:600px; margin:auto;\">\n",
    "                            <img src=\"data:image/jpeg;base64,{logo_b64}\" style=\"width:100%; height:auto; user-drag:none; pointer-events:none;\">\n",
    "                        </div>\n",
    "                        \"\"\")\n",
    "            \n",
    "\n",
    "        with gr.Column(elem_classes=[\"equal-column\"]):\n",
    "            # T√≠tulo y descripci√≥n\n",
    "            gr.Markdown('# Actividad \"Speech and Text Analytics\"')\n",
    "            gr.Markdown(\"## Ejercicio #1\\n\")\n",
    "            \n",
    "            gr.Markdown(\"## üé§ Voz a Texto\")\n",
    "            gr.Markdown(f\"**üìÅ Las grabaciones se guardadan en:**\")\n",
    "            # full_path = os.path.join(os.path.dirname(os.path.abspath(RECORDINGS_DIR)), RECORDINGS_DIR)\n",
    "            gr.Textbox(value = os.path.abspath(RECORDINGS_DIR),\n",
    "                       label = \"üìÅ Ruta de grabaciones\",\n",
    "                       interactive = False)\n",
    "\n",
    "    # =================================================================================\n",
    "    # SECCI√ìN DE ENTRADA - Dise√±o de dos columnas para diferentes m√©todos de entrada\n",
    "    # =================================================================================\n",
    "    with gr.Row(elem_classes=\"center-wrapper\"): # Contenedor horizontal en fila\n",
    "        with gr.Column(elem_classes=[\"equal-column\"]): # Columna de la izquierda para grabaci√≥n con micr√≥fono\n",
    "            gr.Markdown(\"### Opci√≥n 1: Grabar con Micr√≥fono\")\n",
    "\n",
    "            # Componente de grabador de audio\n",
    "            # sources=[\"microphone\"] - Habilitar solo grabaci√≥n con micr√≥fono\n",
    "            # type=\"filepath\"        - El componente retorna la ruta al archivo de audio temporal\n",
    "            # label=\"Grabar Audio\"   - Etiqueta de visualizaci√≥n para el componente\n",
    "            audio_input = gr.Audio(sources = [\"microphone\"],\n",
    "                                   type = \"filepath\",\n",
    "                                   label = 'Grabar Audio')\n",
    "\n",
    "        with gr.Column(elem_classes=[\"equal-column\"]): # Columna de la derecha para subir ficheros\n",
    "            gr.Markdown(\"### Opci√≥n 2: Subir fichero de Audio\")\n",
    "            \n",
    "            # Componente de subida de ficheros\n",
    "            # label=\"Subir fichero de Audio\" - Etiqueta de visualizaci√≥n\n",
    "            # file_types - Lista de formatos de audio soportados\n",
    "            # type=\"filepath\" - Retorna ruta al archivo subido\n",
    "            \n",
    "            file_input = gr.File(label = \"Fichero de Audio (.wav .mp3 .m4a .flac .ogg .acc))\",\n",
    "                                 file_types = [\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\", \".aac\"],\n",
    "                                 type = \"filepath\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # BOT√ìN DE ACCI√ìN\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Bot√≥n de acci√≥n principal que activa la transcripci√≥n\n",
    "    # variant=\"primary\" - Estilo para que destaque como acci√≥n principal\n",
    "    with gr.Row(elem_classes=\"center-wrapper\"):\n",
    "        with gr.Column(elem_classes=[\"span-two-columns\"]):\n",
    "            transcribe_btn = gr.Button(\"Transcribir\",\n",
    "                                       variant = \"primary\",\n",
    "                                       elem_id = \"transcribe-btn\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # SECCI√ìN DE SALIDA - Dise√±o de dos columnas para resultados\n",
    "    # ========================================================================\n",
    "    with gr.Row(elem_classes=\"center-wrapper\"):\n",
    "        output_text = gr.Textbox(label=\"Transcripci√≥n\", lines=5)         # Columna izquierda: Texto de transcripci√≥n\n",
    "        file_info = gr.Textbox(label=\"Informaci√≥n del archivo\", lines=5) # Columna derecha..: Informaci√≥n del fichero\n",
    "\n",
    "    # ========================================================================\n",
    "    # CONEXI√ìN BOT√ìN ‚Üí FUNCI√ìN\n",
    "    # MANEJO DE EVENTOS - Conectar clic del bot√≥n a la funci√≥n\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Cuando se hace clic en transcribe_btn:\n",
    "    # 1. Llama la funci√≥n transcribe_audio()\n",
    "    # 2. Pasa el audio_input y file_input como argumentos\n",
    "    # 3. Actualiza el output_text y file_info con los valores de retorno de la funci√≥n\n",
    "    transcribe_btn.click(\n",
    "        transcribe_audio,\n",
    "        inputs=[audio_input, file_input],\n",
    "        outputs=[output_text, file_info])\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Team Credits\n",
    "    # ============================================================================\n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"\"\"\n",
    "        <div style='text-align: center; padding: 20px;'>\n",
    "            <h3>üë®‚Äçüíª Development Team</h3>\n",
    "            <p><strong>ü§ñ Lead Developer:</strong> Riccardo</p>\n",
    "            <p><strong>üìà Data Scientist:</strong> Carlos and Juan</p>\n",
    "            <p><strong>üîß ML Engineer:</strong> Nicolas</p>\n",
    "            <br>\n",
    "            <p>üì¨ Contact: obstfmgrupo1@gmail.com | üåê Website: <a href='https://i.ibb.co/WNRC7fPn/text2speech.jpg'>Speech 2 Text</a></p>\n",
    "            <p>üíª <a href='https://github.com/whaleskin/Speech2Text.git'>GitHub Repository</a></p>\n",
    "            <p style='color: gray; font-size: 12px;'>¬© 2026 OBS Grupo 1 - TRANSCRIPCI√ìN DE VOZ A TEXTO. All rights reserved.</p>\n",
    "        </div>\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "af0a4542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Puerto 7860 est√° ocupado, probando siguiente...\n",
      "‚ùå Puerto 7861 est√° ocupado, probando siguiente...\n",
      "‚ùå Puerto 7862 est√° ocupado, probando siguiente...\n",
      "‚úÖ Available port: 7863\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Verifica si hay un puerto disponible\n",
    "# ============================================\n",
    "\n",
    "def find_available_port(start_port: int = 7860, max_attempts: int = 100):\n",
    "    \"\"\"Find an available port starting from start_port.\"\"\"\n",
    "    for port in range(start_port, start_port + max_attempts):\n",
    "        # Verificar r√°pidamente si el puerto est√° disponible\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            sock.settimeout(1)\n",
    "            if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
    "                    print(f\"‚ùå Puerto {port} est√° ocupado, probando siguiente...\")\n",
    "                    continue\n",
    "            else:\n",
    "                return port\n",
    "\n",
    "# Asigna el puerto a una variable para ser usado por Gradio\n",
    "available_port = find_available_port(7860)\n",
    "print(f\"‚úÖ Available port: {available_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ea0bd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directorio actual: c:\\Users\\castr\\Desktop\\syncSchool\\OBS\\10_Speech-Next_Analytics\n",
      "Carpeta de grabaciones: ./recordings/\n",
      "\n",
      "Iniciando aplicaci√≥n...\n",
      "URL: http://localhost:7863\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANTE: Para detener la aplicaci√≥n correctamente:\n",
      "1. Haz clic en el bot√≥n DETENER en VS Code\n",
      "2. O Presiona Ctrl+C en la terminal\n",
      "3. Espera 5 segundos antes de reiniciar\n",
      "\n",
      "La aplicaci√≥n permanecer√° abierta hasta que la detengas.\n",
      "\n",
      "üöÄ INICIANDO APLICACI√ìN DE TRANSCRIPCI√ìN\n",
      "==================================================\n",
      "üåê URL: http://localhost:7863\n",
      "üé§ Modelo: Whisper-small\n",
      "üíª Dispositivo: cuda\n",
      "==================================================\n",
      "\n",
      "üìã INSTRUCCIONES:\n",
      "1. Graba audio con el micr√≥fono\n",
      "2. O sube un archivo de audio\n",
      "3. Haz clic en 'Transcribir'\n",
      "\n",
      "üõë PARA DETENER: Usa el bot√≥n DETENER en VS Code\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://a228b9657bfe73ef9e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a228b9657bfe73ef9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7863 <> https://a228b9657bfe73ef9e.gradio.live\n",
      "\n",
      "‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ\n",
      "‚úÖ APLICACI√ìN FINALIZADA CORRECTAMENTE\n",
      "‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ\n",
      "\n",
      "üìä RESUMEN:\n",
      "‚Ä¢ Archivos procesados en: c:\\Users\\castr\\Desktop\\syncSchool\\OBS\\10_Speech-Next_Analytics\\_recordings\n",
      "‚Ä¢ Puedes volver a ejecutar el programa cuando quieras\n",
      "‚Ä¢ Los archivos se mantienen para futuras transcripciones\n",
      "\n",
      "üëã ¬°Gracias por usar el transcriptor de voz!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7 LANZAMIENTO DE LA APLICACI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Bloque de ejecuci√≥n principal - solo se ejecuta cuando el script se ejecuta directamente\n",
    "    (no cuando se importa como un m√≥dulo)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mostrar informaci√≥n del sistema para el usuario\n",
    "    print(f\"\\nDirectorio actual: {os.getcwd()}\")  # Mostrar d√≥nde se guardar√°n los archivos\n",
    "    print(\"Carpeta de grabaciones: ./recordings/\")  # Ruta relativa a las grabaciones\n",
    "    \n",
    "    print(\"\\nIniciando aplicaci√≥n...\")  # Notificaci√≥n de lanzamiento\n",
    "    print(f\"URL: http://localhost:{available_port}\")  # URL de acceso local\n",
    "    \n",
    "    # Instrucciones para el usuario para apagado adecuado\n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANTE: Para detener la aplicaci√≥n correctamente:\")\n",
    "    print(\"1. Haz clic en el bot√≥n DETENER en VS Code\")\n",
    "    print(\"2. O Presiona Ctrl+C en la terminal\")\n",
    "    print(\"3. Espera 5 segundos antes de reiniciar\")\n",
    "    print(\"\\nLa aplicaci√≥n permanecer√° abierta hasta que la detengas.\")\n",
    "    \n",
    "    print(\"\\nüöÄ INICIANDO APLICACI√ìN DE TRANSCRIPCI√ìN\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üåê URL: http://localhost:{available_port}\")\n",
    "    print(\"üé§ Modelo: Whisper-small\")\n",
    "    print(f\"üíª Dispositivo: {device}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nüìã INSTRUCCIONES:\")\n",
    "    print(\"1. Graba audio con el micr√≥fono\")\n",
    "    print(\"2. O sube un archivo de audio\")\n",
    "    print(\"3. Haz clic en 'Transcribir'\")\n",
    "    print(\"\\nüõë PARA DETENER: Usa el bot√≥n DETENER en VS Code\")\n",
    "    \n",
    "    launched_successfully = False\n",
    "    try:\n",
    "        # Lanzar la aplicaci√≥n web de Gradio\n",
    "        # server_name=\"127.0.0.1\"  - Solo localhost (no accesible desde la red)\n",
    "        # server_port=7860         - Puerto por defecto de Gradio\n",
    "        # show_error=True          - Mostrar errores en la UI\n",
    "        # quiet=False              - Mostrar mensajes de inicio de Gradio\n",
    "        # share=True               - Crear URL p√∫blica temporal (accesible desde internet)\n",
    "        # debug=True               - Habilitar modo depuraci√≥n\n",
    "        # prevent_thread_lock=True - Permite que VS Code detenga la aplicaci√≥n correctamente\n",
    "        \n",
    "        demo.launch(server_name = \"127.0.0.1\", \n",
    "                    server_port = available_port, #show_error = True, quiet = False, prevent_thread_lock = True)  # Importante: permite que VS Code lo detenga\n",
    "                    share = True,\n",
    "                    debug = True)\n",
    "        launched_successfully = True\n",
    "    except KeyboardInterrupt:\n",
    "        # Manejar interrupci√≥n manual (Ctrl+C)\n",
    "        print(\"\\n\\nAplicaci√≥n detenida por el usuario.\")\n",
    "    except Exception as e:\n",
    "        # Manejar otras excepciones\n",
    "        print(f\"\\nError: {e}\")\n",
    "        \n",
    "        # Manejo especial para cuando el puerto 7860 est√° en uso\n",
    "        if \"7860\" in str(e):\n",
    "            print(f\"¬°El puerto {available_port} est√° ocupado!\")\n",
    "            print(\"Se han probando hasta 100 puertos...\")\n",
    "            print(\"Soluci√≥n: Cierra VS Code y reinicia el programa.\")\n",
    "    finally:\n",
    "        # ESTO SIEMPRE SE EJECUTA, INCLUYDO CUANDO VS CODE DETIENE\n",
    "        if launched_successfully:\n",
    "            print(\"\\n\" + \"‚úÖ\" * 20)\n",
    "            print(\"‚úÖ APLICACI√ìN FINALIZADA CORRECTAMENTE\")\n",
    "            print(\"‚úÖ\" * 20)\n",
    "            print(\"\\nüìä RESUMEN:\")\n",
    "            print(f\"‚Ä¢ Archivos procesados en: {os.path.abspath(RECORDINGS_DIR)}\")\n",
    "            print(\"‚Ä¢ Puedes volver a ejecutar el programa cuando quieras\")\n",
    "            print(\"‚Ä¢ Los archivos se mantienen para futuras transcripciones\")\n",
    "            print(\"\\nüëã ¬°Gracias por usar el transcriptor de voz!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387c6f3",
   "metadata": {},
   "source": [
    "### eof()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
